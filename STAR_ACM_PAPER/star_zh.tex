%%
%% STAR: Semantic Table Aggregation and Representation via
%% Clustering and Weighted Fusion for Table Retrieval
%%
% \documentclass[sigconf,review,anonymous]{acmart}
\documentclass[sigconf, review]{acmart}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{ulem}
\usepackage{xcolor}
\usepackage{graphicx}

\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

\usepackage{xeCJK}
\setCJKmainfont[AutoFakeBold=2,AutoFakeSlant=.4]{AR PL UKai TW}
\setmainfont{Times New Roman}
\XeTeXlinebreaklocale "zh" %這兩行一定要加，中文才能自動換行
\XeTeXlinebreakskip = 0pt plus 1pt

\begin{document}

% \title{STAR: Semantic Table Representation via Clustering and Attention-based Fusion for Table Retrieval}
\title{STAR: Semantic Table Aggregation and Representation via Clustering and Weighted Fusion for Table Retrieval}


%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Shui-Hsiang Hsu}
\affiliation{%
  \institution{National Chung Hsing University}
  \city{Taichung}
  \country{Taiwan}}
\email{g113056055@smail.nchu.edu.tw}

\author{Tsung-Hsiang Chou}
\affiliation{%
  \institution{National Chung Hsing University}
  \city{Taichung}
  \country{Taiwan}}
\email{yumeow0122@smail.nchu.edu.tw}

\author{Chen-Jui Yu}
\affiliation{%
  \institution{National Chung Hsing University}
  \city{Taichung}
  \country{Taiwan}}
\email{rui0828@smail.nchu.edu.tw}

\author{Yao-Chung Fan}
\affiliation{%
  \institution{National Chung Hsing University}
  \city{Taichung}
  \country{Taiwan}}
\email{yfan@nchu.edu.tw}

\begin{abstract}
Table retrieval is the task of retrieving the most relevant tables from large-scale corpora given natural language queries. However, structural and semantic discrepancies between unstructured text and structured tables make embedding alignment particularly challenging.
Recent methods such as QGpT attempt to enrich table semantics by generating synthetic questions, yet they still rely on coarse partial-table sampling and simple fusion strategies, which limit semantic diversity and hinder effective query–table alignment.
We propose STAR (Semantic Table Aggregation and Representation), a lightweight framework that improves table representation through semantic clustering and weighted fusion.
STAR first applies header-aware K-means clustering to group semantically similar rows and selects representative centroid instances to construct a diverse partial table.
It then generates cluster-specific synthetic questions to comprehensively cover the table's semantic space.
Finally, STAR employs weighted fusion strategies (Fixed Weight Fusion and Dynamic Weight Fusion) to integrate table and query embeddings, enabling fine-grained semantic alignment.
This design enables STAR to capture complementary information from structured and textual sources, improving the expressiveness of table representations.
Experiments on five benchmarks show that STAR achieves consistently higher Recall than QGpT on most datasets, with improvements of up to 17\% on R@1 and 20\% on R@5, demonstrating the effectiveness of semantic clustering and weighted fusion for robust table representation.
\end{abstract}

%% CCS Concepts
\begin{CCSXML}
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10002951.10003317.10003318</concept_id>
<concept_desc>Information systems~Document representation</concept_desc>
<concept_significance>500</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Information systems~Document representation}
\end{CCSXML}

\ccsdesc[500]{Information systems~Information retrieval}
\ccsdesc[500]{Information systems~Retrieval models and ranking}

%% Keywords
\keywords{Table Retrieval, Semantic Representation, Clustering Methods, Adaptive Fusion, Large Language Models}

\maketitle

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.

\section{Introduction}
\label{sec:introduction}

表格檢索在問答系統和知識提取中扮演重要角色。近期研究透過大型語言模型（LLMs）生成合成問題（synthetic questions）來豐富表格的語義表示。QGpT\cite{liang-etal-2025-improving-table}從表格中抽取部分列（partial table）並生成相關問題，試圖在查詢與表格之間建立語義橋樑。然而，QGpT存在兩個關鍵缺陷：\textbf{(1) 啟發式的top-k採樣}可能導致語義冗餘；\textbf{(2) 簡單的拼接融合}缺乏細粒度語義整合。

針對這些問題，我們提出STAR（\textbf{S}emantic \textbf{T}able \textbf{A}ggregation and \textbf{R}epresentation）。STAR包含兩個核心模組：\textbf{(1) Semantic Clustering and Query Generation (SCDG)}採用header-aware K-means聚類確保實例的代表性和多樣性，並為不同聚類分別生成synthetic questions；\textbf{(2) Weighted Fusion (WF)}透過Fixed/Dynamic Weight Fusion實現table和queries的細粒度語義整合。實驗表明，STAR在五個基準資料集上顯著優於QGpT。


\section{Related Works}
\label{sec:related}

早期表格檢索方法基於稀疏檢索（如BM25\cite{robertson2009probabilistic}），後演變為密集檢索\cite{karpukhin2020dense}和結構感知編碼（如TaBERT\cite{yin2020tabert}）。查詢生成技術（GPL\cite{wang2022gpl}、InPars\cite{bonifacio2022inpars}）被用於資料增強。QGpT\cite{liang-etal-2025-improving-table}首次將LLM應用於表格合成問題生成，但採用簡單的top-k採樣和拼接融合，限制了表達能力。本文首次將聚類技術\cite{liu2004cluster}應用於表格實例選擇，提升partial table的代表性。


\section{Methodology}
\label{sec:methodology}

給定表格 $\mathcal{T}$ 包含表頭 $\mathcal{H}$ 和 $n$ 個實例 $\{\mathbf{r}_1, \ldots, \mathbf{r}_n\}$，以及使用者查詢 $q$，表格檢索的目標是從語料庫 $\mathcal{C}$ 中檢索與 $q$ 最相關的表格。STAR包含兩個核心模組：(1) Semantic Clustering and Query Generation (SCDG)；(2) Weighted Fusion (WF)。

\subsection{Semantic Clustering and Query Generation (SCDG)}

QGpT採用top-k策略選取前k列作為partial table，可能造成語義冗餘。SCDG透過語義聚類和聚類引導的查詢生成解決此問題。

\begin{figure*}[t]
\centering
\includegraphics[width=0.9\textwidth]{star_test.png}
\caption{QGpT與STAR的partial table構建與query generation對比。上方展示QGpT的啟發式top-k採樣方法，下方展示STAR的語義聚類方法，不同顏色代表不同的語義聚類。}
\label{fig:comparison}
\end{figure*}

\textbf{Header-aware K-means Clustering:}
使用embedding模型（BGE-M3）對表頭 $\mathcal{H}$ 和每行 $\mathbf{r}_i$ 編碼：
\begin{equation}
\mathbf{e}_i = \alpha \cdot \text{Encoder}(\mathcal{H}) + (1-\alpha) \cdot \text{Encoder}(\mathbf{r}_i)
\end{equation}
其中 $\alpha=0.2$ 控制header和row的相對重要性。對 $\{\mathbf{e}_1, \ldots, \mathbf{e}_n\}$ 進行K-means聚類，分為 $k$ 個聚類 $\{C_1, \ldots, C_k\}$。對每個聚類 $C_j$，選取距離聚類中心最近的實例：
\begin{equation}
\mathbf{r}_j^* = \arg\min_{\mathbf{r}_i \in C_j} \|\mathbf{e}_i - \boldsymbol{\mu}_j\|^2
\end{equation}
構建partial table $\mathcal{T}_{partial} = \{\mathbf{r}_1^*, \ldots, \mathbf{r}_k^*\}$ 既保持語義多樣性又具代表性。

\textbf{Clustering-Guided Query Generation:}
對每個聚類 $C_j$，構建clustered table $\mathcal{T}_j = \{\mathcal{H}, \mathbf{r} \mid \mathbf{r} \in C_j\}$，使用LLM生成synthetic question $q_j = \text{LLM}(\text{Prompt}(\mathcal{T}_j))$。生成 $k$ 個questions $\{q_1, \ldots, q_k\}$，全面覆蓋表格語義空間。

\subsection{Weighted Fusion}

分別編碼partial table和synthetic questions：
\begin{align}
\mathbf{e}_{\text{table}} &= \text{Encoder}(\mathcal{T}_{partial}), \quad
\mathbf{e}_{\text{queries}} = \text{Encoder}(q_1 \oplus \cdots \oplus q_k)
\end{align}
最終表示為 $\mathbf{e}_{\mathcal{T}} = w_t \cdot \mathbf{e}_{\text{table}} + w_q \cdot \mathbf{e}_{\text{queries}}$（$w_t + w_q = 1$）。

\textbf{Fixed Weight Fusion (FWF):} 固定權重 $w_t = \alpha$（$\alpha=0.7$）。

\textbf{Dynamic Weight Fusion (DWF):} 根據相似度 $s = \cos(\mathbf{e}_{\text{table}}, \mathbf{e}_{\text{queries}})$ 動態分配：$w_q = \beta \cdot s$，$w_t = 1 - w_q$（$\beta=0.3$）。

\section{Experiments}
\label{sec:experiments}

\subsection{實驗設置}

\textbf{資料集：}Mimo (ch/en)、OTTQA\cite{chenopen}、FetaQA\cite{nan2022fetaqa}、E2E-WTQ\cite{pasupat2015compositional}。\textbf{Baselines：}QGpT\cite{liang-etal-2025-improving-table}。\textbf{實現：}BGE-M3\cite{xiao2023cpack}作為encoder，Llama 3.1 8B-Instruct生成queries，$k=10$，$\alpha=0.2$，FWF中table權重0.7，DWF中$\beta=0.3$。評估指標：Recall@1/5/10。

\subsection{主要實驗結果}

如表\ref{tab:main_results}所示，STAR在所有五個資料集上均優於QGpT。在E2E-WTQ上，STAR (FWF)的R@1達58.51\%，比QGpT的41.49\%提升17.02個百分點。在Mimo (en)上，STAR (DWF)的R@1達58.89\%，提升8.23個百分點。DWF在Mimo和OTTQA上略優於FWF，驗證了語義自適應權重的有效性。STAR在所有資料集上的一致改進證明了其穩健性。

\section{Analysis}
\label{sec:analysis}

\subsection{消融實驗}

表\ref{tab:ablation}展示了STAR各元件的重要性。移除SCDG後，平均R@1從51.86\%降至47.07\%（-4.79\%），證明語義聚類和聚類引導查詢生成的有效性。移除WF後，R@1降至49.08\%（-2.78\%），驗證了細粒度語義整合的重要性。兩個模組協同使STAR有效表示表格語義。

\subsection{權重策略分析}

如表\ref{tab:weight_analysis}所示，FWF在$\alpha=0.7$時效能最佳（R@1=51.62\%）。權重過低（0.1）或過高（0.9）均降低效能，表明table和queries需適當平衡。DWF達到R@1=51.86\%，與最佳FWF相當，證明語義自適應權重分配的有效性。

\section{Conclusion}
\label{sec:conclusion}

本文提出STAR框架，透過語義聚類和加權融合提升表格表示品質。SCDG使用header-aware K-means確保實例的代表性和多樣性，並為不同聚類生成synthetic questions。WF透過Fixed/Dynamic Weight Fusion實現細粒度語義整合。實驗表明STAR在五個資料集上顯著優於QGpT（平均R@1提升6.39個百分點）。未來工作包括：端到端learned weighting、動態聚類數量確定、多模態擴展。

% 插入表格
\input{tables}

\section*{Acknowledgments}
This work was supported in part by the National Science and Technology Council, Taiwan, under Grants NSTC 113-2221-E-005-056-MY3 and NSTC 113-2634-F-005-001.

\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

\end{document}
\endinput
%%
%% End of file `sample-sigconf.tex'.