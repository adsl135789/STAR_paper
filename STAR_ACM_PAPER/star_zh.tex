%%
%% STAR: Semantic Table Aggregation and Representation via
%% Clustering and Weighted Fusion for Table Retrieval
%%
% \documentclass[sigconf,review,anonymous]{acmart}
\documentclass[sigconf, review]{acmart}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{ulem}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{newunicodechar}

\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

\usepackage{xeCJK}
\setCJKmainfont[AutoFakeBold=2,AutoFakeSlant=.4]{AR PL UKai TW}
\setmainfont{Times New Roman}
\newfontfamily{\fallbackfont}{DejaVu Sans}
\newunicodechar{✓}{{\fallbackfont ✓}}
\newunicodechar{✗}{{\fallbackfont ✗}}
\XeTeXlinebreaklocale "zh" %這兩行一定要加，中文才能自動換行
\XeTeXlinebreakskip = 0pt plus 1pt

\setcopyright{none}  % 移除版權聲明
\settopmatter{printacmref=false}  % 移除摘要下方的引用資訊
\renewcommand\footnotetextcopyrightpermission[1]{}  % 移除第一欄的版權註腳
\pagestyle{plain}  % 移除頁首頁尾的會議資訊

\begin{document}

\setcopyright{acmlicensed}
\copyrightyear{2026}
\acmYear{2026}
\acmDOI{TBD}
\acmConference[TheWebConf '26]{The Web Conference 2026}{April 13–17, 2026}{Dubai, UAE}
\acmISBN{TBD}

% \title{STAR: Semantic Table Representation via Clustering and Attention-based Fusion for Table Retrieval}
\title{STAR: Semantic Table Aggregation and Representation via Clustering and Weighted Fusion for Table Retrieval}


%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Shui-Hsiang Hsu}
\affiliation{%
  \institution{National Chung Hsing University}
  \city{Taichung}
  \country{Taiwan}}
\email{g113056055@smail.nchu.edu.tw}

\author{Tsung-Hsiang Chou}
\affiliation{%
  \institution{National Chung Hsing University}
  \city{Taichung}
  \country{Taiwan}}
\email{yumeow0122@smail.nchu.edu.tw}

\author{Chen-Jui Yu}
\affiliation{%
  \institution{National Chung Hsing University}
  \city{Taichung}
  \country{Taiwan}}
\email{rui0828@smail.nchu.edu.tw}

\author{Yao-Chung Fan}
\affiliation{%
  \institution{National Chung Hsing University}
  \city{Taichung}
  \country{Taiwan}}
\email{yfan@nchu.edu.tw}

\begin{abstract}
Table retrieval is the task of retrieving the most relevant tables from large-scale corpora given natural language queries. However, structural and semantic discrepancies between unstructured text and structured tables make embedding alignment particularly challenging.
Recent methods such as QGpT attempt to enrich table semantics by generating synthetic questions, yet they still rely on coarse partial-table sampling and simple fusion strategies, which limit semantic diversity and hinder effective query–table alignment.
We propose STAR (Semantic Table Aggregation and Representation), a lightweight framework that improves table representation through semantic clustering and weighted fusion.
STAR first applies header-aware K-means clustering to group semantically similar rows and selects representative centroid instances to construct a diverse partial table.
It then generates cluster-specific synthetic questions to comprehensively cover the table's semantic space.
Finally, STAR employs weighted fusion strategies (Fixed Weight Fusion and Dynamic Weight Fusion) to integrate table and query embeddings, enabling fine-grained semantic alignment.
This design enables STAR to capture complementary information from structured and textual sources, improving the expressiveness of table representations.
Experiments on five benchmarks show that STAR achieves consistently higher Recall than QGpT on most datasets, with improvements of up to 17\% on R@1 and 20\% on R@5, demonstrating the effectiveness of semantic clustering and weighted fusion for robust table representation.
\end{abstract}

\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10002951.10003317.10003318</concept_id>
       <concept_desc>Information systems~Document representation</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10002951.10003317.10003338</concept_id>
       <concept_desc>Information systems~Retrieval models and ranking</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Information systems~Document representation}
\ccsdesc[500]{Information systems~Retrieval models and ranking}

%% Keywords
\keywords{Table Retrieval, Semantic Representation, Clustering Methods, Adaptive Fusion, Large Language Models}

\maketitle

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.

\section{Introduction}
\label{sec:introduction}

表格檢索（Table Retrieval）目標是從大規模表格語料庫中檢索回與使用者自然語言查詢最相關的表格。然而，自然語言查詢與結構化表格之間存在顯著語義落差\cite{huang2022mixed}，使得傳統密集檢索方法效果不彰。此外，實際應用中的表格往往包含大量列與欄，完整展平成文字後容易超出編碼器的 token 長度限制，進一步加劇了 query–table alignment 的困難。

為了在上述語義落差與長表格情境下改善表格表示，近期研究嘗試透過語義擴增來緩解這些問題。從語料庫端出發，QGpT\cite{liang-etal-2025-improving-table} 採用兩階段設計：首先僅選取表格前 $k$ 列構成 partial table，以在 token 限制下取得表格的近似表示；接著利用 LLM 為Partial Table 生成 synthetic queries，將結構化的表格內容擴展為自然語言表示，使其更容易與自然語言查詢進行密集語義匹配。然而，QGpT 在兩個關鍵面向上仍有侷限：(1) \textbf{啟發式的實例選擇：}採用簡單的 top-$k$ 策略僅保留表格前 $k$ 列，缺乏對整體表格的代表性；(2) \textbf{粗糙的表示融合策略：}將 partial table 與 synthetic queries 直接串接為單一序列送入同一編碼器，使兩種訊號在向量空間中被混合處理，無法顯式調整它們對最終表格表示的相對貢獻。

針對這些問題，我們提出 STAR（\textbf{S}emantic \textbf{T}able \textbf{A}ggregation and \textbf{R}epresentation），在不修改 retriever 架構的前提下，重新設計表格側的語義聚合與表示方式。STAR 分為兩個階段：首先，Semantic Clustering and Query Generation (SCQG) 階段使用 header-aware K-means 聚類，確保選取的實例具有代表性與多樣性，並為每個聚類分別生成 synthetic queries，以更全面地覆蓋表格的語義空間；其次，Weighted Fusion (WF) 階段分別編碼 partial table 與 synthetic queries，並以加權方式融合兩種訊號，以取得更精確的語義表示。在五個基準資料集上的實驗顯示，STAR 在多數設定下均優於 QGpT，驗證了語義聚類與加權融合的有效性。


\section{Related Works}
\label{sec:related}

早期表格檢索方法主要依賴稀疏檢索技術，如BM25\cite{robertson2009probabilistic}，透過詞彙匹配計算相關性，但難以捕捉深層語義關聯。隨著深度學習的發展，密集檢索方法\cite{karpukhin-etal-2020-dense}透過學習文本的向量表示實現語義匹配，並逐漸被應用於表格檢索任務。為了更好地處理表格的結構特性，一些研究提出了結構感知的表格編碼方法\cite{herzig2020tapas,yin-etal-2020-tabert}，而近期研究轉向利用查詢生成進行語義增強，透過生成式模型為文件產生偽查詢來改善檢索效果\cite{mao-etal-2021-generation,wang-etal-2022-gpl,bonifacio2022inpars}。在表格檢索領域，由於完整表格往往超出編碼器的token限制，QGpT\cite{liang-etal-2025-improving-table}提出選取partial table作為代表性實例，並首次系統地應用LLM為其生成synthetic questions來豐富表格語義表示。

然而，QGpT採用簡單的top-k採樣策略，缺乏語義多樣性；且直接拼接table和queries，無法細粒度建模不同資訊來源的重要性。本文透過header-aware聚類確保實例多樣性，並提出加權融合策略實現細粒度語義整合。


\section{Methodology}
\label{sec:methodology}

給定一個包含表頭（header）$\mathcal{H}$ 和 $n$ 個實例（instances）$\{\mathbf{r}_1, \mathbf{r}_2, \ldots, \mathbf{r}_n\}$ 的表格 $\mathcal{T}$，以及一個使用者查詢 $q$，表格檢索的目標是從語料庫 $\mathcal{C}$ 中檢索出與 $q$ 最相關的表格。STAR框架分為兩個階段：(1) Semantic Clustering and Query Generation (SCQG)，以及 (2) Weighted Fusion (WF)。

\subsection{Semantic Clustering and Query Generation (SCQG)}

如圖\ref{fig:comparison} (Stage 1) 所示，QGpT採用簡單的top-k策略選取表格的前k個實例作為partial table。為了解決其實例選擇缺乏多樣性以及查詢生成覆蓋不全面的問題，我們提出SCQG階段，結合語義聚類和聚類引導的查詢生成。

\begin{figure*}[t!]
\centering
\includegraphics[width=1.0\textwidth]{star_v4.png}
\caption{QGpT與STAR的兩階段對比。\textbf{Stage 1:} Instance Selection \& Query Generation；\textbf{Stage 2:} Encoding策略。不同顏色代表不同的語義聚類。}
\label{fig:comparison}
\end{figure*}

\subsubsection{Header-aware K-means Clustering}
我們首先使用預訓練的編碼器分別對表頭 $\mathcal{H}$ 和每個實例 $\mathbf{r}_i$ 進行編碼，得到header embedding $\mathbf{e}_{\mathcal{H}}$ 和instance embedding $\mathbf{e}_{\mathbf{r}_i}$：
\begin{align}
\mathbf{e}_{\mathcal{H}} &= \text{Encoder}(\mathcal{H}) \\
\mathbf{e}_{\mathbf{r}_i} &= \text{Encoder}(\mathbf{r}_i)
\end{align}

然後，我們將這兩個embedding進行加權融合，構成header-aware representation：
\begin{equation}
\mathbf{e}_i = \alpha \cdot \mathbf{e}_{\mathcal{H}} + (1-\alpha) \cdot \mathbf{e}_{\mathbf{r}_i}
\end{equation}
其中 $\alpha$ 是控制header和instance相對重要性的超參數。此設計結合了實例語義與表頭結構資訊。

接下來，我們對所有實例的embedding $\{\mathbf{e}_1, \mathbf{e}_2, \ldots, \mathbf{e}_n\}$ 進行K-means聚類，將其分為 $k$ 個聚類 $\{C_1, C_2, \ldots, C_k\}$。對於每個聚類 $C_j$，我們選取距離聚類中心最近的實例作為該聚類的代表（centroid instance）：
\begin{equation}
\mathbf{r}_j^* = \arg\min_{\mathbf{r}_i \in C_j} \|\mathbf{e}_i - \boldsymbol{\mu}_j\|^2
\end{equation}
其中 $\boldsymbol{\mu}_j$ 是聚類 $C_j$ 的中心向量。透過這種方式，我們構建的partial table $\mathcal{T}_{partial} = \{\mathbf{r}_1^*, \mathbf{r}_2^*, \ldots, \mathbf{r}_k^*\}$ 既保持了語義多樣性（來自不同聚類），又具有代表性（每個聚類的中心實例）。

\subsubsection{Clustering-Guided Query Generation}
對於每個聚類 $C_j$，我們構建一個clustered table $\mathcal{T}_j = \{\mathcal{H}, \mathbf{r} \mid \mathbf{r} \in C_j\}$，並使用LLM為其生成一個synthetic query $q_j$：
\begin{equation}
q_j = \text{LLM}(\text{Prompt}(\mathcal{T}_j))
\end{equation}

這樣，我們為每個表格 $\mathcal{T}$ 生成 $k$ 個synthetic queries $\{q_1, q_2, \ldots, q_k\}$，每個query都對應一個特定的語義聚類。相比QGpT對top-k採樣的partial table生成queries，我們的cluster-specific生成策略能確保queries覆蓋表格不同語義聚類所代表的多樣化方面，從而充當使用者查詢與表格之間的語義橋樑。

\subsection{Weighted Fusion}

如圖\ref{fig:comparison} (Stage 2) 所示，QGpT採用簡單的串接策略，將partial table和synthetic queries串接後送入同一個編碼器得到單一表示。這種方法將不同資訊來源混合在一起，缺乏對各部分語義重要性的建模。相比之下，我們提出加權融合策略，分別編碼table和queries，然後進行加權融合。

具體而言，我們首先分別編碼partial table（包含表頭與選出的代表實例）和所有synthetic queries的串接：
\begin{align}
\mathbf{e}_{\text{table}} &= \text{Encoder}(\mathcal{T}_{partial}) \\
\mathbf{e}_{\text{queries}} &= \text{Encoder}(q_1 \oplus q_2 \oplus \cdots \oplus q_k)
\end{align}

最終的表格表示透過加權融合得到：
\begin{equation}
\mathbf{e}_{\mathcal{T}} = w_t \cdot \mathbf{e}_{\text{table}} + w_q \cdot \mathbf{e}_{\text{queries}}
\end{equation}
其中 $w_t$ 和 $w_q$ 分別是table和queries的權重，且 $w_t + w_q = 1$。我們設計了兩種權重分配策略：

\subsubsection{Fixed Weight Fusion (FWF)}
給予table固定權重 $w_t = \lambda$，剩餘權重分配給queries：$w_q = 1-\lambda$。這種方法簡單直觀，透過調整 $\lambda$ 可以控制table和queries在最終表示中的相對重要性。

\subsubsection{Dynamic Weight Fusion (DWF)}
根據table和queries之間的語義相似度動態分配權重。我們使用cosine similarity計算相似度：
\begin{equation}
s = \cos(\mathbf{e}_{\text{table}}, \mathbf{e}_{\text{queries}})
\end{equation}

權重透過相似度計算：
\begin{equation}
w_q = \beta \cdot s, \quad w_t = 1 - w_q
\end{equation}
其中 $\beta$ 是控制query embedding權重範圍的超參數。相似度 $s$ 反映了synthetic queries與table的語義一致性，我們據此動態調整兩者的權重比例。

\section{Experiments}
\label{sec:experiments}

\subsection{Experimental Setup}

\subsubsection{Datasets}
我們在五個廣泛使用的表格檢索基準資料集上評估STAR：
(1) \textbf{Mimo (ch)}\cite{li-etal-2025-mimotable}：中文表格檢索資料集；
(2) \textbf{Mimo (en)}\cite{li-etal-2025-mimotable}：英文表格檢索資料集；
(3) \textbf{OTTQA}\cite{chen2021open}：開放域表格問答資料集；
(4) \textbf{FetaQA}\cite{nan-etal-2022-fetaqa}：基於表格的問答資料集；
(5) \textbf{E2E-WTQ}\cite{pasupat-liang-2015-compositional}：端到端的表格問答資料集。

\subsubsection{Baselines}
我們與QGpT\cite{liang-etal-2025-improving-table}進行比較，該方法使用LLM生成synthetic queries進行表格檢索。

\subsubsection{Implementation}
為了公平比較，我們遵循QGpT的原始實驗設置。使用BGE-M3作為編碼器，使用Llama 3.1 8B-Instruct作為synthetic query generation的生成模型。聚類數量 $k$ 設置為10，因此為每個表格生成10個queries。在header-aware K-means clustering中，我們設置 $\alpha=0.2$；在Fixed Weight Fusion中，我們設置 $\lambda=0.7$；在Dynamic Weight Fusion中，我們設置 $\beta=0.5$。所有實驗使用Recall@K ($K \in \{1, 5, 10\}$)作為評估指標。

\subsection{Main Experimental Results}

% 主要實驗結果表格
\begin{table*}[t]
\centering
\caption{Performance comparison on five datasets. Bold: best, underlined: second-best.}
\label{tab:main_results}
\small
\setlength{\tabcolsep}{4pt}
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{l*{18}{c}}
\toprule
\textbf{Method} &
\multicolumn{3}{c}{\textbf{Mimo (ch)}} &
\multicolumn{3}{c}{\textbf{Mimo (en)}} &
\multicolumn{3}{c}{\textbf{OTTQA}} &
\multicolumn{3}{c}{\textbf{FetaQA}} &
\multicolumn{3}{c}{\textbf{E2E-WTQ}} &
\multicolumn{3}{c}{\textbf{Avg.}} \\
\cmidrule(lr){2-4} \cmidrule(lr){5-7} \cmidrule(lr){8-10} \cmidrule(lr){11-13} \cmidrule(lr){14-16} \cmidrule(lr){17-19}
& R@1 & R@5 & R@10 & R@1 & R@5 & R@10 & R@1 & R@5 & R@10 & R@1 & R@5 & R@10 & R@1 & R@5 & R@10 & R@1 & R@5 & R@10 \\
\midrule
QGpT & 49.81 & 71.06 & 77.23 & 50.66 & 72.35 & 80.80 & 51.45 & 78.14 & 86.68 & 33.95 & 50.87 & 57.86 & 41.49 & 65.98 & 72.61 & 45.47 & 67.88 & 75.04 \\
STAR (FWF) & \uline{51.36} & \textbf{72.16} & \textbf{78.08} & \uline{58.34} & \uline{76.98} & \uline{82.50} & \uline{53.84} & \textbf{80.17} & \textbf{88.17} & \uline{36.00} & \textbf{54.92} & \textbf{62.21} & \textbf{58.51} & \textbf{85.89} & \uline{90.04} & \uline{51.61} & \textbf{74.02} & \uline{80.20} \\
STAR (DWF) & \textbf{51.58} & \uline{72.15} & \uline{77.99} & \textbf{58.89} & \textbf{77.72} & \textbf{82.89} & \textbf{54.07} & \uline{79.99} & \uline{88.08} & \textbf{36.25} & \uline{54.77} & \textbf{62.21} & \textbf{58.51} & \uline{85.06} & \textbf{90.06} & \textbf{51.86} & \uline{73.94} & \textbf{80.12} \\
\bottomrule
\end{tabular}
\end{table*}

表\ref{tab:main_results}展示了STAR與QGpT在五個資料集上的比較結果，以及五個資料集的平均效能。我們可以觀察到以下幾點：

\textbf{(1) STAR整體顯著優於QGpT：}從平均效能來看，STAR (DWF)在R@1上達到51.86\%，相比QGpT的45.47\%提升了6.39個百分點；STAR (FWF)在R@5上達到74.02\%，相比QGpT的67.88\%提升了6.14個百分點；STAR (DWF)在R@10上達到80.12\%，相比QGpT的75.04\%提升了5.08個百分點。在個別資料集上，改進幅度更為顯著。特別是在E2E-WTQ資料集上表現最為突出，STAR (FWF)在R@1上達到58.51\%，相比QGpT的41.49\%提升了17.02個百分點；在R@5上達到85.89\%，相比QGpT的65.98\%提升了19.91個百分點。在Mimo (en)資料集上，STAR (DWF)在R@1上達到58.89\%，相比QGpT的50.66\%提升了8.23個百分點。這些結果充分驗證了我們提出的語義聚類和加權融合策略的有效性。

\textbf{(2) FWF與DWF的比較：}兩種加權融合策略在不同資料集上表現相近，各有優勢。從平均效能來看，Dynamic Weight Fusion在R@1和R@10上略優，而Fixed Weight Fusion在R@5上表現更佳。在Mimo和OTTQA資料集上，Dynamic Weight Fusion略優於Fixed Weight Fusion，這表明根據語義相似度自適應調整權重確實有效。然而，Fixed Weight Fusion憑藉其簡單性和穩定性，在E2E-WTQ等資料集上也取得了競爭力的結果。整體而言，兩種策略的平均R@1僅相差0.25個百分點，展現了相當的效能。

\textbf{(3) 跨資料集的穩健性：}STAR在所有五個資料集上都取得了一致的改進，證明了我們的方法具有良好的泛化能力，能夠處理不同語言（中文、英文）和不同類型的表格檢索任務。平均提升幅度在R@1、R@5、R@10三個指標上均超過5個百分點，顯示出STAR的穩定性與實用性。

\section{Analysis}
\label{sec:analysis}

\subsection{Ablation Study of STAR Components}

% Ablation Study 表格 1
\begin{table}[t]
\centering
\caption{Ablation study (avg. across five datasets).}
\label{tab:ablation}
\small
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{l@{\hskip 10pt}c@{\hskip 10pt}c@{\hskip 10pt}c}
\toprule
\textbf{Method} & \textbf{R@1} & \textbf{R@5} & \textbf{R@10} \\
\midrule
STAR (full) & \textbf{51.86} & \textbf{73.94} & \textbf{80.25} \\
\quad w/o SCQG & 47.07 {\scriptsize\color{red}(-4.79)} & 68.43 {\scriptsize\color{red}(-5.51)} & 75.88 {\scriptsize\color{red}(-4.37)} \\
\quad w/o WF & 49.08 {\scriptsize\color{red}(-2.78)} & 69.69 {\scriptsize\color{red}(-4.25)} & 77.02 {\scriptsize\color{red}(-3.23)} \\
\quad w/o Header-aware & 50.57 {\scriptsize\color{red}(-1.29)} & 73.63 {\scriptsize\color{red}(-0.31)} & 79.922 {\scriptsize\color{red}(-0.33)} \\
\bottomrule
\end{tabular}
\end{table}

為了驗證STAR各個元件的有效性，我們進行了消融實驗。表\ref{tab:ablation}展示了五個資料集上的平均Recall指標。

我們比較了以下變體：
(1) \textbf{STAR (full)}：完整模型，使用Dynamic Weight Fusion；
(2) \textbf{w/o SCQG}：移除Semantic Clustering and Query Generation階段，使用QGpT的top-k採樣和直接query generation；
(3) \textbf{w/o WF}：移除Weighted Fusion，使用簡單的拼接策略；
(4) \textbf{w/o Header-aware}：移除Header-aware K-means clustering中的header資訊，僅使用實例embedding進行聚類。

實驗結果表明：

\textbf{(1) SCQG階段的重要性：}移除SCQG階段後（w/o SCQG），平均R@1從51.86\%下降至47.07\%，下降了4.79個百分點。這證明了使用語義聚類方法選擇多樣化實例和引導查詢生成的有效性。

\textbf{(2) Weighted Fusion的貢獻：}移除加權融合策略後（w/o WF），平均R@1從51.86\%下降至49.08\%，下降了2.78個百分點。這驗證了細粒度的語義整合對於構建高品質表格表示的重要性。

\textbf{(3) Header-aware聚類的有效性：}移除header資訊後（w/o Header-aware），平均R@1從51.86\%下降至50.57\%，下降了1.29個百分點。雖然下降幅度相對較小，但這仍然證明了在K-means聚類中融入表頭資訊的重要性。Header-aware設計能夠使聚類過程同時考慮實例的語義內容與表格的結構資訊，從而選出更具代表性的實例，提升整體表格表示的品質。

\subsection{Effect of Fusion Weighting Strategies}

% Ablation Study 表格 2
\begin{table}[t]
\centering
\caption{Weight strategy analysis (avg. across five datasets).}
\label{tab:weight_analysis}
\small
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{l@{\hskip 10pt}c@{\hskip 10pt}c@{\hskip 10pt}c}
\toprule~
\textbf{Method} & \textbf{R@1} & \textbf{R@5} & \textbf{R@10} \\
\midrule
FWF ($\lambda$=0.1) & 46.61 & 68.76 & 76.22 \\
FWF ($\lambda$=0.3) & 49.25 & 71.66 & 78.65 \\
FWF ($\lambda$=0.5) & 51.33 & 73.27 & 79.81 \\
FWF ($\lambda$=0.7) & \uline{51.62} & \textbf{74.02} & \uline{80.20} \\
FWF ($\lambda$=0.9) & 48.61 & 72.22 & 79.28 \\
\midrule
DWF & \textbf{51.86} & \uline{73.94} & \textbf{80.25} \\
\bottomrule
\end{tabular}
\end{table}

表\ref{tab:weight_analysis}展示了不同權重設置對STAR效能的影響。我們測試了五種不同的Fixed Weight Fusion設置以及Dynamic Weight Fusion。

\textbf{Fixed Weight Fusion (FWF)}
在Fixed Weight Fusion中，$\lambda=0.7$時效能最佳，平均R@1達到51.62\%。當table權重過低（0.1）或過高（0.9）時，效能都會下降，這表明table和queries需要適當的平衡。

\textbf{Dynamic Weight Fusion (DWF)}
Dynamic Weight Fusion取得了與最佳Fixed Weight相當的效能（平均R@1為51.86\%），證明了動態、語義aware的權重分配機制的有效性。這種自適應方法能夠根據不同表格和查詢的語義關係自動調整權重，無需手動調參。

\section{Conclusion}
\label{sec:conclusion}

本文針對現有表格檢索方法中存在的啟發式採樣和粗糙融合問題，提出了STAR框架。STAR透過兩個階段提升表格表示的品質：Semantic Clustering and Query Generation階段使用header-aware K-means聚類選取多樣化實例並生成cluster-specific synthetic questions；Weighted Fusion階段透過加權融合策略實現table和queries的細粒度語義整合。在五個基準資料集上的實驗表明，STAR在大多數情況下顯著優於QGpT，平均R@1提升6.39個百分點，驗證了語義聚類和加權融合的有效性。

未來的研究方向包括探索端到端的learned weighting機制，透過訓練自動學習最優權重分配。

\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

\end{document}
\endinput
%%
%% End of file `sample-sigconf.tex'.